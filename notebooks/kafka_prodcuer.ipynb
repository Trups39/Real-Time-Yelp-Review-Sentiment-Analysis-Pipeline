{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install confluent_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from confluent_kafka import Producer\n",
    "\n",
    "#Setup kafka producer config\n",
    "\n",
    "conf = {\n",
    "    \"bootstrap.servers\":\"<YOUR_KAFKA_BOOTSTRAP_SERVER>\",\n",
    "    \"security.protocol\":\"SASL_SSL\",\n",
    "    \"sasl.mechanisms\":\"PLAIN\",\n",
    "    \"sasl.username\":\"<KAFKA_API_KEY>\",\n",
    "    \"sasl.password\":\"<KAFKA_API_SECRET>\",\n",
    "    \"client.id\":\"json-serial-producer\"\n",
    "}\n",
    "\n",
    "producer = Producer(conf)\n",
    "\n",
    "#Topic name\n",
    "topic = \"raw_topic\"\n",
    "\n",
    "#Delivery report callback\n",
    "def delivery_report(err,msg):\n",
    "    if err:\n",
    "        print(f\"Message delivery failed: {err}\")\n",
    "    else:\n",
    "        print(f\"Message delivered successfully! Key: {msg.key()}\")\n",
    "\n",
    "#Read checkpoint        \n",
    "def read_checkpoint(checkpoint_file):\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as file:\n",
    "            return int(file.read().strip())\n",
    "    return 0\n",
    "\n",
    "#Write checkpoint\n",
    "def write_checkpoint(checkpoint_file,index):\n",
    "    with open(checkpoint_file, 'w') as file:\n",
    "        file.write(str(index))\n",
    "    print(f\"Checkpoint updated to line: {index}\")\n",
    "#Handle date    \n",
    "def handle_date(obj):\n",
    "    if isinstance(obj, pd.Timestamp):\n",
    "        return obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    raise TypeError(f\"Object of type {type(obj).__name__} is not JSON serializable\")\n",
    "    \n",
    "#Stream JSON serially\n",
    "def stream_json_serially(file_path,checkpoint_file='/kaggle/working/checkpoint.txt'):\n",
    "    last_sent_index = read_checkpoint(checkpoint_file)\n",
    "    \n",
    "    with open(file_path,'r') as file:\n",
    "        for idx,line in enumerate(file):\n",
    "            if idx < last_sent_index:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "                producer.produce(\n",
    "                    topic,\n",
    "                    key=str(record['review_id']),\n",
    "                    value=json.dumps(record,default=handle_date).encode('utf-8'),\n",
    "                    callback=delivery_report\n",
    "                )\n",
    "                \n",
    "                producer.flush()\n",
    "                \n",
    "                write_checkpoint(checkpoint_file, idx + 1)\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Failed to decode JSON: {e}\")\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    stream_json_serially('/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
